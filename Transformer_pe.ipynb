{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "medieval-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ExponentialLR, CosineAnnealingLR, StepLR, OneCycleLR\n",
    "\n",
    "from dataloader import Dataset_AMEX\n",
    "from metric import AmexMetric\n",
    "from model_pe import Transformer\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consecutive-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset_AMEX('val')\n",
    "# y_true = torch.tensor(dataset[0][1], dtype=torch.float)[None]\n",
    "\n",
    "# model = Transformer(num_tokens=1,\n",
    "#         feat_dim=188,\n",
    "#         embed_dim = 64,\n",
    "#         num_heads=4,\n",
    "#         num_encoder_layers=2,\n",
    "#         dropout_p=0.3)\n",
    "# y_hats = model(torch.tensor(dataset[0][0])[None])\n",
    "# loss_fn = nn.BCELoss(reduction=\"mean\")\n",
    "# loss_fn(y_hats.squeeze(1), y_true)\n",
    "# #val_amex_metric = AmexMetric()\n",
    "# #val_amex_metric.update(y_hats.reshape(-1), y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-budget",
   "metadata": {},
   "source": [
    "# Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "civilian-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pl(pl.LightningDataModule):\n",
    "    def __init__(self, fold):\n",
    "        super().__init__()\n",
    "        self.fold = 1\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage= None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_set = Dataset_AMEX('train', fold=self.fold)\n",
    "            self.val_set = Dataset_AMEX('val', fold=self.fold)\n",
    "        if stage == \"validate\":\n",
    "            self.val_set = Dataset_AMEX('val', fold=self.fold)\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.val_set = Dataset_AMEX('val', fold=self.fold)\n",
    "        if stage == \"predict\" or stage is None:\n",
    "            self.test_set = Dataset_AMEX('test')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=512, shuffle=True, num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=2048, shuffle=False, num_workers=1)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=4096, shuffle=False, num_workers=1)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=4096, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-bathroom",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stupid-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_transformer(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-3):#, batch_size):\n",
    "        super().__init__()\n",
    "        self.model = Transformer(num_tokens=1,\n",
    "                        feat_dim=188,\n",
    "                        embed_dim = 64,\n",
    "                        num_heads=4,\n",
    "                        num_encoder_layers=2,\n",
    "                        dropout_p=0.3)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_amex_metric = AmexMetric()\n",
    "        self.val_amex_metric = AmexMetric()\n",
    "        self.loss_fn = nn.BCELoss(reduction=\"mean\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        y_hat = self.model(x)\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        x, y = batch\n",
    "        x, y = x.float(), y.float()\n",
    "        y_hat = self.model(x)\n",
    "        # loss function\n",
    "        loss = self.loss_fn(y_hat.squeeze(1), y)\n",
    "        self.train_amex_metric.update(y_hat.squeeze(1), y)\n",
    "        self.log_dict({'train_loss': loss, 'train_amex_metric': self.train_amex_metric}, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        x, y = batch\n",
    "        x, y = x.float(), y.float()\n",
    "        y_hat = self.model(x)\n",
    "        # loss function\n",
    "        loss = self.loss_fn(y_hat.squeeze(1), y)\n",
    "        self.val_amex_metric.update(y_hat.squeeze(1), y)\n",
    "        self.log_dict({'val_loss': loss, 'val_amex_metric': self.val_amex_metric}, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'loss': loss}       \n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        x, y = batch\n",
    "        x, y = x.float(), y.float()\n",
    "        y_hat = self.model(x)\n",
    "        # loss function\n",
    "        #loss = self.loss_fn(y_hats.squeeze(1), y_true)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        x, y = batch\n",
    "        x, y = x.float(), y.float()\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.model(x)#.squeeze(1)\n",
    "        return y_hat\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = OneCycleLR(optimizer, max_lr=1e-3, epochs=25, steps_per_epoch=718) #steps_per_epoch=len(dataloader)\n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-tamil",
   "metadata": {},
   "source": [
    "# Find LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "refined-slave",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# dm = Dataset_pl(1)\n",
    "# model = Model_transformer()#, argv['batch_size']) \n",
    "# trainer = pl.Trainer(gpus=2, strategy='dp')\n",
    "# lr_finder = trainer.tuner.lr_find(model, dm)\n",
    "\n",
    "# # Results can be found in\n",
    "# lr_finder.results\n",
    "\n",
    "# # Plot with\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()\n",
    "\n",
    "# # Pick point based on plot, or get suggestion\n",
    "# new_lr = lr_finder.suggestion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-hammer",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "approved-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm = Dataset_pl(1)\n",
    "# model = Model_transformer()#, argv['batch_size']) \n",
    "\n",
    "# wandb_logger = WandbLogger(project=\"AMEX\")\n",
    "# callbacks=[ModelCheckpoint(dirpath='ckpt', \n",
    "#                            monitor=\"val_amex_metric\", mode=\"max\")]\n",
    "\n",
    "# trainer = pl.Trainer(gpus=[1], max_epochs=30, \n",
    "#                     logger=wandb_logger, callbacks=callbacks,\n",
    "#                     enable_progress_bar=False)\n",
    "\n",
    "# trainer.fit(model, datamodule=dm)\n",
    "\n",
    "# # get validation metrics\n",
    "# val = trainer.validate(model, datamodule=dm, ckpt_path='best')\n",
    "# val_amex_metric_epoch = val[0]['val_amex_metric_epoch']\n",
    "\n",
    "# # get output\n",
    "# output = trainer.predict(model, datamodule=dm, ckpt_path='best')\n",
    "# output = torch.vstack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-studio",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Training data shapes (367131, 13, 188) (367131,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name              | Type        | Params\n",
      "--------------------------------------------------\n",
      "0 | model             | Transformer | 509 K \n",
      "1 | train_amex_metric | AmexMetric  | 0     \n",
      "2 | val_amex_metric   | AmexMetric  | 0     \n",
      "3 | loss_fn           | BCELoss     | 0     \n",
      "--------------------------------------------------\n",
      "509 K     Trainable params\n",
      "0         Non-trainable params\n",
      "509 K     Total params\n",
      "2.037     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation data shapes (91782, 13, 188) (91782,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /RP1/mydocker/Ben/amex/ckpt/epoch=24-step=17950.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from checkpoint at /RP1/mydocker/Ben/amex/ckpt/epoch=24-step=17950.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation data shapes (91782, 13, 188) (91782,)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  val_amex_metric_epoch     0.7779491559726072\n",
      "     val_loss_epoch         0.22833910584449768\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 20/20 [00:02<00:00,  7.55it/s]\n",
      "Restoring states from the checkpoint path at /RP1/mydocker/Ben/amex/ckpt/epoch=24-step=17950.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from checkpoint at /RP1/mydocker/Ben/amex/ckpt/epoch=24-step=17950.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Test data shapes (924621, 13, 188) (210,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 0.7779491559726072\n"
     ]
    }
   ],
   "source": [
    "val_metrics = []\n",
    "outputs = []\n",
    "for i in range(1,11):\n",
    "    dm = Dataset_pl(i)\n",
    "    model = Model_transformer()#, argv['batch_size']) \n",
    "\n",
    "    #wandb_logger = WandbLogger(project=\"AMEX\")\n",
    "    callbacks=[ModelCheckpoint(dirpath='ckpt', \n",
    "                               monitor=\"val_amex_metric\", mode=\"max\")]\n",
    "\n",
    "#     trainer = pl.Trainer(gpus=[1], max_epochs=25, \n",
    "#                         logger=wandb_logger, callbacks=callbacks,\n",
    "#                         enable_progress_bar=False)\n",
    "    trainer = pl.Trainer(gpus=[1], max_epochs=25, \n",
    "                         callbacks=callbacks,\n",
    "                         enable_progress_bar=False)\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "\n",
    "    # get validation metrics\n",
    "    val = trainer.validate(model, datamodule=dm, ckpt_path='best')\n",
    "    val_amex_metric_epoch = val[0]['val_amex_metric_epoch']\n",
    "    \n",
    "    # get output\n",
    "    output = trainer.predict(model, datamodule=dm, ckpt_path='best')\n",
    "    output = torch.vstack(output)\n",
    "    # save result\n",
    "    val_metrics.append(val_amex_metric_epoch)\n",
    "    outputs.append(output)\n",
    "    \n",
    "    print(f\"fold {i}\", val_amex_metric_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-ready",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-kansas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-laundry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-chemical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-links",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-double",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-warning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fft",
   "language": "python",
   "name": "fft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
